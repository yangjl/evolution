---
title: "Testing GAN for our data"
output: NULL
---


# Creat the environment on crane for the GAN

```{bash}
# training:me
conda env create -f evolution_env.yml 
conda activate me
conda list # list the software
```

#
# To activate this environment, use
#
#     $ conda activate tf-env
#
# To deactivate an active environment, use
#
#     $ conda deactivate

# Utilizing Anaconda Environments in JupyterHub

https://newsroom.unl.edu/announce/holland/7344/41179

4. Install the ipykernal package into the active environment with the command `conda install ipykernel`.
5. Install the kernel specification with the command 'python -m ipykernel install --user --name me --display-name "Python (me)"'
6. Add any other desired packages and deactivate the environment with `conda deactivate`.

The previous steps will be sufficient to make the conda environment available to local Jupyter Notebooks.

To make your conda environments accessible from SLURM Notebooks, enter the following commands:
mkdir -p $WORK/.jupyter
mv ~/.local/share/jupyter/kernels $WORK/.jupyter
ln -s $WORK/.jupyter/kernels ~/.local/share/jupyter/kernels

Note: This last step only needs to be done once. Any future created environments will automatically be accessible from SLURM notebooks once this is done.

To check that your environment has been created correctly, login to JupyterHub and select a Jupyter Notebook job profile. Create a new notebook using the environment by selecting the correct entry in the `New` drop-down menu in the top right corner.


```{bash}

```


```{bash}
# /work/jyanglab/jyang21/projects/evolution/manuscript_code
srun --partition=gpu --gres=gpu --mem=4gb --ntasks-per-node=2 --nodes=1 --pty $SHELL
```

# Scripts

The script 'train_gan.py' to train a generative model of regulatory DNA can be run via:

```{bash}
python train_gan.py --generic True

python train_gan.py --data_loc "SeqsData" --log_name "gan_bal_200d" --train_iters 300000 --max_seq_len 1000 --latent_dim 200 --balanced_bins --seed 111
```

where the folder SeqsData contains the training, validation and test sequence datasets in plain .txt files (e.g. train_data.txt, test_data.txt, valid_data.txt). Please see the script for further details on possible parameters.

The script 'optimize_gan.py' to optimize a trained generator with a predictive model to obtain an ExpressionGAN  can be run via:

```python optimize_gan.py --log_name "gan_bal_200d_opt" --generator "gen_path/trained_gan.ckpt.meta" --predictor "pred_path" --iterations 100000 --target 'max' --seed 222```

Please see the script for further details on possible parameters.


usage: train_gan.py [-h] [--generic] [--data_loc DATA_LOC]
                    [--data_start DATA_START] [--log_dir LOG_DIR]
                    [--log_name LOG_NAME] [--checkpoint CHECKPOINT]
                    [--model_type MODEL_TYPE] [--train_iters TRAIN_ITERS]
                    [--disc_iters DISC_ITERS]
                    [--checkpoint_iters CHECKPOINT_ITERS]
                    [--latent_dim LATENT_DIM] [--gen_dim GEN_DIM]
                    [--disc_dim DISC_DIM] [--gen_layers GEN_LAYERS]
                    [--disc_layers DISC_LAYERS] [--batch_size BATCH_SIZE]
                    [--max_seq_len MAX_SEQ_LEN] [--vocab VOCAB]
                    [--vocab_order VOCAB_ORDER] [--annotate] [--validate]
                    [--balanced_bins] [--learning_rate LEARNING_RATE]
                    [--lmbda LMBDA] [--seed SEED]

optional arguments:
  -h, --help            show this help message and exit
  --generic             Generate generic data on the fly (ignores data_loc and
                        data_start args)
  --data_loc DATA_LOC   Data location
  --data_start DATA_START
                        Line number to start when parsing data (useful for
                        ignoring header)
  --log_dir LOG_DIR     Base log folder
  --log_name LOG_NAME   Name to use when logging this model
  --checkpoint CHECKPOINT
                        Filename of checkpoint to load
  --model_type MODEL_TYPE
                        Which type of model architecture to use (resnet or
                        mlp)
  --train_iters TRAIN_ITERS
                        Number of iterations to train GAN for
  --disc_iters DISC_ITERS
                        Number of iterations to train discriminator for at
                        each training step
  --checkpoint_iters CHECKPOINT_ITERS
                        Number of iterations before saving checkpoint
  --latent_dim LATENT_DIM
                        Size of latent space
  --gen_dim GEN_DIM     Generator dimension parameter
  --disc_dim DISC_DIM   Discriminator dimension parameter
  --gen_layers GEN_LAYERS
                        How many layers for generator
  --disc_layers DISC_LAYERS
                        How many layers for discriminator
  --batch_size BATCH_SIZE
                        Batch size
  --max_seq_len MAX_SEQ_LEN
                        Maximum sequence length of data
  --vocab VOCAB         Which vocabulary to use. Options are 'dna', 'rna',
                        'dna_nt_only', and 'rna_nt_only'.
  --vocab_order VOCAB_ORDER
                        Specific order for the one-hot encodings of vocab
                        characters
  --annotate            Include annotation as part of training/generation
                        process?
  --validate            Whether to use validation set
  --balanced_bins       Whether to use balanched bins batches
  --learning_rate LEARNING_RATE
                        Learning rate for the optimizer
  --lmbda LMBDA         Lipschitz penalty hyperparameter
  --seed SEED           Random seed

